{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/anaconda3/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: tpot in /opt/anaconda3/lib/python3.12/site-packages (0.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from tpot) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from tpot) (1.5.1)\n",
      "Requirement already satisfied: deap>=1.2 in /opt/anaconda3/lib/python3.12/site-packages (from tpot) (1.4.2)\n",
      "Requirement already satisfied: update-checker>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from tpot) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in /opt/anaconda3/lib/python3.12/site-packages (from tpot) (4.66.5)\n",
      "Requirement already satisfied: stopit>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tpot) (1.1.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /opt/anaconda3/lib/python3.12/site-packages (from tpot) (2.2.2)\n",
      "Requirement already satisfied: joblib>=0.13.2 in /opt/anaconda3/lib/python3.12/site-packages (from tpot) (1.4.2)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tpot) (2.1.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24.2->tpot) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=0.24.2->tpot) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn>=1.4.1->tpot) (3.5.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from update-checker>=0.16->tpot) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install matplotlib tpot\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10회차 과제\n",
    "목표: KNN을 이용한 모델을 만들되, grid search를 사용하여 hyperparameter를 결정하고 K-fold cross validation(K=10)으로 테스트하기.  \n",
    "(수업 자료의 `과제 연계 실습` 참고)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 와인 분류하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 와인과 관련한 여러 정보와 음용 가능 여부가 담긴 데이터이다.  \n",
    "KNN과 grid search를 사용하여 종류('target')를 예측하되, 최소 95%의 정확도(K-fold cross validation, K=10 기준)를 달성하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     target  alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  \\\n",
       "0         0    14.23        1.71  2.43               15.6      127.0   \n",
       "1         0    13.20        1.78  2.14               11.2      100.0   \n",
       "2         0    13.16        2.36  2.67               18.6      101.0   \n",
       "3         0    14.37        1.95  2.50               16.8      113.0   \n",
       "4         0    13.24        2.59  2.87               21.0      118.0   \n",
       "..      ...      ...         ...   ...                ...        ...   \n",
       "173       2    13.71        5.65  2.45               20.5       95.0   \n",
       "174       2    13.40        3.91  2.48               23.0      102.0   \n",
       "175       2    13.27        4.28  2.26               20.0      120.0   \n",
       "176       2    13.17        2.59  2.37               20.0      120.0   \n",
       "177       2    14.13        4.10  2.74               24.5       96.0   \n",
       "\n",
       "     total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  \\\n",
       "0             2.80        3.06                  0.28             2.29   \n",
       "1             2.65        2.76                  0.26             1.28   \n",
       "2             2.80        3.24                  0.30             2.81   \n",
       "3             3.85        3.49                  0.24             2.18   \n",
       "4             2.80        2.69                  0.39             1.82   \n",
       "..             ...         ...                   ...              ...   \n",
       "173           1.68        0.61                  0.52             1.06   \n",
       "174           1.80        0.75                  0.43             1.41   \n",
       "175           1.59        0.69                  0.43             1.35   \n",
       "176           1.65        0.68                  0.53             1.46   \n",
       "177           2.05        0.76                  0.56             1.35   \n",
       "\n",
       "     color_intensity   hue  od280/od315_of_diluted_wines  proline  \n",
       "0               5.64  1.04                          3.92   1065.0  \n",
       "1               4.38  1.05                          3.40   1050.0  \n",
       "2               5.68  1.03                          3.17   1185.0  \n",
       "3               7.80  0.86                          3.45   1480.0  \n",
       "4               4.32  1.04                          2.93    735.0  \n",
       "..               ...   ...                           ...      ...  \n",
       "173             7.70  0.64                          1.74    740.0  \n",
       "174             7.30  0.70                          1.56    750.0  \n",
       "175            10.20  0.59                          1.56    835.0  \n",
       "176             9.30  0.60                          1.62    840.0  \n",
       "177             9.20  0.61                          1.60    560.0  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00130048, 0.00070255, 0.000611  , 0.00060475, 0.0006089 ,\n",
       "        0.00061443, 0.00062733, 0.00059519, 0.00059514, 0.00059595]),\n",
       " 'std_fit_time': array([5.48995546e-04, 1.24909860e-04, 1.30321654e-05, 1.27482617e-05,\n",
       "        1.21113118e-05, 1.52864987e-05, 8.75347441e-05, 1.04916095e-05,\n",
       "        7.51665382e-06, 8.91647236e-06]),\n",
       " 'mean_score_time': array([0.00131872, 0.00074494, 0.00066936, 0.00067306, 0.00067677,\n",
       "        0.00068617, 0.00066411, 0.00066686, 0.0006583 , 0.0006789 ]),\n",
       " 'std_score_time': array([3.28906591e-04, 1.60171094e-04, 1.22544598e-05, 1.14097677e-05,\n",
       "        2.00331770e-05, 3.45481602e-05, 2.21673512e-05, 1.18035257e-05,\n",
       "        1.07115766e-05, 2.55417970e-05]),\n",
       " 'param_model__n_neighbors': masked_array(data=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value=999999),\n",
       " 'params': [{'model__n_neighbors': 1},\n",
       "  {'model__n_neighbors': 2},\n",
       "  {'model__n_neighbors': 3},\n",
       "  {'model__n_neighbors': 4},\n",
       "  {'model__n_neighbors': 5},\n",
       "  {'model__n_neighbors': 6},\n",
       "  {'model__n_neighbors': 7},\n",
       "  {'model__n_neighbors': 8},\n",
       "  {'model__n_neighbors': 9},\n",
       "  {'model__n_neighbors': 10}],\n",
       " 'split0_test_score': array([0.83333333, 0.88888889, 0.94444444, 0.88888889, 1.        ,\n",
       "        0.94444444, 1.        , 0.94444444, 1.        , 0.94444444]),\n",
       " 'split1_test_score': array([0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 1.        , 1.        ]),\n",
       " 'split2_test_score': array([0.94444444, 0.94444444, 0.88888889, 0.94444444, 0.94444444,\n",
       "        0.88888889, 0.94444444, 0.88888889, 0.94444444, 0.94444444]),\n",
       " 'split3_test_score': array([0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444]),\n",
       " 'split4_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split5_test_score': array([0.94444444, 0.88888889, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.88888889, 0.88888889, 0.94444444, 0.94444444]),\n",
       " 'split6_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split7_test_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split8_test_score': array([0.88235294, 0.88235294, 0.88235294, 0.88235294, 0.94117647,\n",
       "        0.94117647, 0.94117647, 0.94117647, 0.94117647, 0.94117647]),\n",
       " 'split9_test_score': array([0.94117647, 0.94117647, 0.94117647, 0.94117647, 0.94117647,\n",
       "        0.94117647, 1.        , 1.        , 1.        , 1.        ]),\n",
       " 'mean_test_score': array([0.94346405, 0.94346405, 0.94901961, 0.94901961, 0.96601307,\n",
       "        0.95490196, 0.96633987, 0.95522876, 0.97745098, 0.97189542]),\n",
       " 'std_test_score': array([0.05045925, 0.0439187 , 0.04000299, 0.04000299, 0.02777586,\n",
       "        0.03357595, 0.0370609 , 0.04167275, 0.02763129, 0.02811977]),\n",
       " 'rank_test_score': array([9, 9, 7, 7, 4, 6, 3, 5, 1, 2], dtype=int32),\n",
       " 'split0_train_score': array([1.     , 0.96875, 0.96875, 0.98125, 0.96875, 0.96875, 0.96875,\n",
       "        0.95625, 0.96875, 0.975  ]),\n",
       " 'split1_train_score': array([1.     , 0.975  , 0.9625 , 0.9625 , 0.96875, 0.96875, 0.96875,\n",
       "        0.96875, 0.975  , 0.98125]),\n",
       " 'split2_train_score': array([1.     , 0.975  , 0.96875, 0.96875, 0.98125, 0.98125, 0.98125,\n",
       "        0.975  , 0.98125, 0.9875 ]),\n",
       " 'split3_train_score': array([1.     , 0.96875, 0.9625 , 0.96875, 0.975  , 0.96875, 0.96875,\n",
       "        0.96875, 0.98125, 0.96875]),\n",
       " 'split4_train_score': array([1.     , 0.96875, 0.96875, 0.975  , 0.975  , 0.975  , 0.975  ,\n",
       "        0.96875, 0.96875, 0.9625 ]),\n",
       " 'split5_train_score': array([1.     , 0.96875, 0.96875, 0.9625 , 0.98125, 0.9875 , 0.98125,\n",
       "        0.98125, 0.98125, 0.98125]),\n",
       " 'split6_train_score': array([1.     , 0.96875, 0.9625 , 0.96875, 0.975  , 0.96875, 0.975  ,\n",
       "        0.96875, 0.975  , 0.975  ]),\n",
       " 'split7_train_score': array([1.     , 0.975  , 0.9625 , 0.9625 , 0.975  , 0.96875, 0.96875,\n",
       "        0.96875, 0.975  , 0.96875]),\n",
       " 'split8_train_score': array([1.        , 0.97515528, 0.97515528, 0.97515528, 0.98136646,\n",
       "        0.97515528, 0.97515528, 0.98136646, 0.98136646, 0.97515528]),\n",
       " 'split9_train_score': array([1.        , 0.97515528, 0.96273292, 0.96273292, 0.97515528,\n",
       "        0.9689441 , 0.97515528, 0.96273292, 0.97515528, 0.9689441 ]),\n",
       " 'mean_train_score': array([1.        , 0.97190606, 0.96628882, 0.96878882, 0.97565217,\n",
       "        0.97315994, 0.97378106, 0.97003494, 0.97627717, 0.97440994]),\n",
       " 'std_train_score': array([0.        , 0.00315651, 0.00415823, 0.00624274, 0.00438808,\n",
       "        0.00627268, 0.00468578, 0.00728308, 0.00468569, 0.00708496])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.0]: 100.000%\n",
      "[[6 0 0]\n",
      " [1 6 0]\n",
      " [0 0 5]]\n",
      "[Fold no.1]: 94.444%\n",
      "[[6 0 0]\n",
      " [1 6 0]\n",
      " [0 0 5]]\n",
      "[Fold no.2]: 94.444%\n",
      "[[6 0 0]\n",
      " [0 6 1]\n",
      " [0 0 5]]\n",
      "[Fold no.3]: 94.444%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.4]: 100.000%\n",
      "[[6 0 0]\n",
      " [0 6 1]\n",
      " [0 0 5]]\n",
      "[Fold no.5]: 94.444%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.6]: 100.000%\n",
      "[[6 0 0]\n",
      " [0 7 0]\n",
      " [0 0 5]]\n",
      "[Fold no.7]: 100.000%\n",
      "[[6 0 0]\n",
      " [1 5 1]\n",
      " [0 0 4]]\n",
      "[Fold no.8]: 88.235%\n",
      "[[5 0 0]\n",
      " [0 8 0]\n",
      " [0 0 4]]\n",
      "[Fold no.9]: 100.000%\n",
      "평균 K-fold cross validation (best model): 96.601%\n"
     ]
    }
   ],
   "source": [
    "raw_wine = datasets.load_wine()\n",
    "wine = pd.DataFrame(raw_wine['data'], index=raw_wine['target'], columns=raw_wine['feature_names'])\n",
    "wine = wine.reset_index(names=['target'] + raw_wine['feature_names'])\n",
    "display(wine)\n",
    "\n",
    "#전 과제에서 갖고옴 \n",
    "new_columns_names = ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
    "\n",
    "\n",
    "X = wine[new_columns_names]\n",
    "y = wine['target']\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = False)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"model\", classifier),\n",
    "])\n",
    "\n",
    "grid_vals = {'model__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "grid_knn = GridSearchCV(estimator=pipe, param_grid=grid_vals, scoring='accuracy', \n",
    "                       cv=kfold, refit=True, return_train_score=True) \n",
    "\n",
    "\n",
    "grid_knn.fit(X, y)\n",
    "display(grid_knn.cv_results_)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = False)\n",
    "\n",
    "accs = []\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(kfold.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_idx, :], X.iloc[test_idx, :]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_test)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    random_knn.best_estimator_.fit(X_train_scaled, y_train)\n",
    "    y_pred = random_knn.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(f\"[Fold no.{fold}]: {accuracy_score(y_test, y_pred)*100:.3f}%\")\n",
    "\n",
    "    accs.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(f\"평균 K-fold cross validation (best model): {sum(accs)/len(accs)*100:.3f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
